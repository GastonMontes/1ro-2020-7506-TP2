{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo los archivos a utilizar. Solo las columnas de mi interés.\n",
    "trainData = pd.read_csv('../Data/train.csv', usecols=['id', 'text', 'target'])\n",
    "testData = pd.read_csv('../Data/test.csv', usecols=['id', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso el train y test set\n",
    "Obtengo el train set como (word, target) y el test set como (id, word)\n",
    "\n",
    "Me fijo cómo es la estructura de cada set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso el train para obtener (word, target)\n",
    "Es una función auxiliar que cambia la estructura del dataset de entrenamiendo de (id, text, target) a (word, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los textos de los tweets en palabras.\n",
    "def splitTrainIntoWords(dataframe):\n",
    "    splitted = pd.DataFrame(dataframe['text'].str.split(' ').to_list(), index=dataframe['id']).stack()\n",
    "    \n",
    "    # Reestablezco el id.\n",
    "    splitted = splitted.reset_index([0, 'id'])\n",
    "\n",
    "    # Le pongo a las segunda columna un nombre descriptivo.\n",
    "    splitted.columns = ['id','word']\n",
    "\n",
    "    # Agrego la columna target haciendo un merge con el set original.\n",
    "    splitted = splitted.merge(dataframe, left_on = 'id', right_on = 'id', how = 'left')\n",
    "\n",
    "    # Elimino la columna text y id.\n",
    "    del splitted['text']\n",
    "    del splitted['id']\n",
    "\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso el test set para obtener (id, word)\n",
    "Es una función auxiliar que cambia la estructura del dataset de test de (id, text) a (id, word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los textos de los tweets en palabras.\n",
    "def splitTestIntoWords(dataframe):\n",
    "    # Creo un nuevo dataframe con las palabras separadas.\n",
    "    splitted = pd.DataFrame(dataframe['text'].str.split(' ').to_list(), index=dataframe['id']).stack()\n",
    "    \n",
    "    # Reestablezco el id.\n",
    "    splitted = splitted.reset_index([0, 'id'])\n",
    "\n",
    "    # Le pongo a las segunda columna un nombre descriptivo.\n",
    "    splitted.columns = ['id','word']\n",
    "\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de entrenamiento\n",
    "Esta función toma el set de entrenamiento del formato (word, target) con el cuál se va a realizar el entrenamiento modelo y devuelve un dataframe entrenado del formato (word, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModelo(train):    \n",
    "    # Agrupo las palabras y hago un promedio del target.\n",
    "    trainedDF = train.groupby('word').mean().reset_index()\n",
    "    \n",
    "    return trainedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de predicción\n",
    "Esta función realiza las predicciones.\n",
    "\n",
    "Recibe un set entrenado con el formaro (word, target) y un set de test con el formato (id, word) sobre el cuál realiza las predicciones.\n",
    "\n",
    "Devuelve un dataframe con las predicciones del tipo (id, predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(trained, test):    \n",
    "    # Mergeo el valor del promedio del target de las palabras en este data set.\n",
    "    testDF = test.merge(trained, left_on = 'word', right_on = 'word', how = 'left')\n",
    "    \n",
    "    # Elimino la columna de las palabras.\n",
    "    del testDF['word']\n",
    "    \n",
    "    # Agrupo por id.\n",
    "    testDF = testDF.groupby('id').mean().reset_index()\n",
    "    \n",
    "    # Paso los valores a 1 y 0 dependiendo si target > 0.5 o < 0.5.\n",
    "    testDF['target'] = testDF['target'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    \n",
    "    return testDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para crear submit.\n",
    "Toma un set de datos de train con formaro (word, target), lo entrena, realiza las predicciones sobre el archivo test con formato (id, word) y guarda un archivo en caso de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarPredecirYGuardar(train, test, csvFileName, save):\n",
    "    trained = entrenarModelo(train)\n",
    "    predicciones = predecir(trained, test)  \n",
    "    \n",
    "    if save:\n",
    "        predicciones.set_index('id').to_csv(csvFileName)\n",
    "    \n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creo funciones que van a ser las que se aplican a los datasets para realizar la optimización.\n",
    "\n",
    "Para mejorar en cada iteración el resultado se crean diferentes funciones que hacen los siguientes cambios:\n",
    "\n",
    "1 - Se pasan todas las palabras a lowercase.\n",
    "\n",
    "2 - Se toman los links como si fueran una sola palabra 'http'.\n",
    "\n",
    "3 - Se quitan los '\\n' encontrados en los textos.\n",
    "\n",
    "4 - Se quitan los stop words.\n",
    "\n",
    "5 - Se quitan de las palabras todos los caracteres que no sean letras y se eliminan las palabras vacías.\n",
    "\n",
    "En cada paso se hará un nuevo submit verificando los resultados obtenidos.\n",
    "\n",
    "## Nomenclatura de los archivos\n",
    "Se tienen 5 funcionas a aplicar a los datasets, entonces los archivos se nombraran como test-xxxxx.csv.\n",
    "\n",
    "Si solo se aplica la función 1 entonces el archivo sera test-00001.csv, si no se aplica ninguna función será test-00000.csv y si se aplican la función 1 y la función 3 será test-00101.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para pasar las palabras a minúsculas\n",
    "Recibe un set de datos con una columna 'word' y devuelve un nuevo set con las palabras en minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabrasALowercase(trained):\n",
    "    lowercasedDF = trained.copy()\n",
    "    \n",
    "    # Paso las palabras a minúsculas.\n",
    "    lowercasedDF['word'] = lowercasedDF['word'].str.lower()\n",
    "    \n",
    "    return lowercasedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para tomar los links como una única palabra 'http'\n",
    "Recibe un set de datos con la columna 'word' y devuelve un nuevo set con los links como si fueran una misma palabra 'http'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linksComoHttp(trained):\n",
    "    httpDF = trained.copy()\n",
    "    \n",
    "    # Todos los links pasan a ser la palabra 'http'.\n",
    "    httpDF.loc[httpDF['word'].str.contains('http', case=True), 'word'] = 'http'\n",
    "    \n",
    "    return httpDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que quita los saltos de línea '\\n'\n",
    "Recibe un set de datos entrenados, un set de test del formato (word, target) o (id, word) y un train set o test set con los la etiquera '\\n' eliminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarEtiquetasTrain(train):\n",
    "    trainDF = train.copy()\n",
    "    trainDF = pd.DataFrame(trainDF['word'].str.split('\\n').to_list(), index=trainDF['target']).stack()\n",
    "    trainDF = trainDF.reset_index([0, 'target'])\n",
    "    trainDF.columns = ['target','word']\n",
    "    trainDF.reset_index()\n",
    "    \n",
    "    return trainDF\n",
    "\n",
    "def eliminarEtiquetasTest(test):\n",
    "    testDF = test.copy()\n",
    "    testDF = pd.DataFrame(testDF['word'].str.split('\\n').to_list(), index=testDF['id']).stack()\n",
    "    testDF = testDF.reset_index([0, 'id'])\n",
    "    testDF.columns = ['id','word']\n",
    "    testDF.reset_index()\n",
    "    \n",
    "    return testDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que quita todos los caracteres que no sean letras de las palabras.\n",
    "Dado un dataframe con la columna 'word', elimina caracteres especiales y borra todas las palabras que sean vacías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarCharsEspeciales(dataframe): \n",
    "    sanDF = dataframe.copy()\n",
    "    sanDF = sanDF[sanDF['word'].str.isspace() == False]\n",
    "    sanDF['word'].replace(regex=True, inplace=True, to_replace='[^A-Za-z]', value=r'')\n",
    "    sanDF = sanDF[sanDF['word'].str.strip().astype(bool)]\n",
    "    \n",
    "    return sanDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para quitar las stop words.\n",
    "Dado un dataframe con la columna 'word', elimina todos los stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarStopWords(dataframe):\n",
    "    stops = stopwords.words('english')\n",
    "    sinStops = dataframe.copy()\n",
    "    sinStops = sinStops[~sinStops['word'].isin(stops)]\n",
    "    return sinStops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submits.\n",
    "A continuación se realizan los submits de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00000.\n",
    "trainSplitted = splitTrainIntoWords(trainData)\n",
    "testSplitted = splitTestIntoWords(testData)\n",
    "entrenarPredecirYGuardar(trainSplitted, testSplitted, 'test-00000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00001.\n",
    "# Se aplica lowercase a las palabras de los dataframes.\n",
    "trainLowercased = palabrasALowercase(trainSplitted)\n",
    "testLowercase = palabrasALowercase(testSplitted)\n",
    "entrenarPredecirYGuardar(trainLowercased, testLowercase, 'test-00001.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00010.\n",
    "# Se toman los links como la palabra 'http'.\n",
    "trainHTTP = linksComoHttp(trainSplitted)\n",
    "testHTTP = linksComoHttp(testSplitted)\n",
    "entrenarPredecirYGuardar(trainHTTP, testHTTP, 'test-00010.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00100.\n",
    "# Se eliminan las etiquetas como '\\n'.\n",
    "trainSinEtiquetas = eliminarEtiquetasTrain(trainSplitted)\n",
    "testSinEtiquetas = eliminarEtiquetasTest(testSplitted)\n",
    "entrenarPredecirYGuardar(trainSinEtiquetas, testSinEtiquetas, 'test-00100.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01000.\n",
    "# Se eliminan las stopwords.\n",
    "trainStops = eliminarStopWords(trainSplitted)\n",
    "testStops = eliminarStopWords(testSplitted)\n",
    "\n",
    "entrenarPredecirYGuardar(trainStops, testStops, 'test-01000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000.\n",
    "# Se eliminan los caracteres especiales y las palabras vacías..\n",
    "trainSan = eliminarCharsEspeciales(trainSplitted)\n",
    "testSan = eliminarCharsEspeciales(testSplitted)\n",
    "entrenarPredecirYGuardar(trainSan, testSan, 'test-10000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search + Cross validation.\n",
    "A continuación se intentaran buscar cuál es la combinación de funciones que mejores predicciones realiza.<br>\n",
    "La idea es buscar, dentro de las 5 funciones declaradas, las funciones que minimizan los errores de predicción. <br>\n",
    "Para cada combinación de funciones se dividirá el set de datos en 10 subsets, se entrenara el algoritmo con 9 subsets y se utilizará el subset restante como set de validación. Este proceso se realizará 10 veces con el fin de que cada subset actue como set de validación.<br>\n",
    "Una vez que se corrieron las 10 iteraciones para cada combinación de funciones, se tomara como resultado el promedio de los valores obtenidos para cada iteración y se elige aquela combinación que mejor resultado logró.\n",
    "\n",
    "## Función que aplica las funciones declaradas \n",
    "Esta función lo que hace es recibir una lista de enteros que indican si la función se debe aplicar o no dependiendo si en la posición se encuentra un 1 o un 0. Por ejemplo: si se recibe la lista [0, 1, 1, 0, 0] esto indica lo siguiente: <br>\n",
    "0 -> No se aplica la función 5.<br>\n",
    "1 -> Se aplica la función 4.<br>\n",
    "1 -> Se aplica la función 3.<br>\n",
    "0 -> No se aplica la función 2.<br>\n",
    "0 -> No se aplica la función 1.<br>\n",
    "\n",
    "El set de entrenamiento y el de test tienen que tener los siguientes formatos: (word, target) y (id, word) respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarFunciones(train, test, funciones):\n",
    "    trainSet = train.copy()\n",
    "    testSet = test.copy()\n",
    "    \n",
    "    if funciones[4]:\n",
    "        trainSet = palabrasALowercase(trainSet)\n",
    "        testSet = palabrasALowercase(testSet)\n",
    "        \n",
    "    if funciones[3]:\n",
    "        trainSet = linksComoHttp(trainSet)\n",
    "        testSet = linksComoHttp(testSet)\n",
    "        \n",
    "    if funciones[2]:\n",
    "        trainSet = eliminarEtiquetasTrain(trainSet)\n",
    "        testSet = eliminarEtiquetasTest(testSet)\n",
    "        \n",
    "    if funciones[1]:\n",
    "        trainSet = eliminarStopWords(trainSet)\n",
    "        testSet = eliminarStopWords(testSet)\n",
    "        \n",
    "    if funciones[0]:\n",
    "        trainSet = eliminarCharsEspeciales(trainSet)\n",
    "        testSet = eliminarCharsEspeciales(testSet)\n",
    "        \n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de evaluación\n",
    "Esta función recibe un dataframe de predicciones (id, target) con su dataframe de validación (id, target). <br>\n",
    "Simplemente valida si se realizó bien o mal la predicción y, mediante los positivos verdaderos, los falsos positivos y falsos negativos, calcula la función F1 de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluarPredicciones(predicciones, validaciones):\n",
    "    verdaderoPositivo = 0\n",
    "    falsoPositivo = 0\n",
    "    falsoNegativo = 0\n",
    "    \n",
    "    for i in range(0, predicciones.shape[0] - 1):\n",
    "        prediccion = predicciones.iloc[i, :]\n",
    "        idPrediccion = prediccion['id']\n",
    "        valorReal = validaciones[validaciones['id'] == idPrediccion].iloc[0,:]\n",
    "\n",
    "        prediccionTarget = prediccion['target']\n",
    "        valorRealTarget = valorReal['target']\n",
    "    \n",
    "        if prediccionTarget == 1 and valorRealTarget == 1:\n",
    "            verdaderoPositivo = verdaderoPositivo + 1\n",
    "            \n",
    "        if prediccionTarget == 1 and valorRealTarget == 0:\n",
    "            falsoPositivo = falsoPositivo + 1\n",
    "                \n",
    "        if prediccionTarget == 0 and valorRealTarget == 1:\n",
    "            falsoNegativo = falsoNegativo + 1\n",
    "    \n",
    "    precision = verdaderoPositivo / (verdaderoPositivo + falsoPositivo)\n",
    "    recall = verdaderoPositivo / (verdaderoPositivo + falsoNegativo)\n",
    "    \n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función cross validation\n",
    "Esta función realiza el proceso de validación para la combinación de funciones recibida. <br>\n",
    "Dado el set de entrenamiento (id, word, target) y el porcentage por el cuál dividir el train divide el set de entrenamiento en dos sub set: set de entrenamiento (uno nuevo, de menor tamaño) y set de validación. <br>\n",
    "A partir del set de validación genera un set de testeo, sobre el cuál se van a realizar las predicciones. <br>\n",
    "Se entrena el modelo con el subset de entrenamiento y se realizan las predicciones sobre el set de testeo. <br>\n",
    "Se itera hasta que todos los subsets que se pueden armar con el porcentage de subsets pasado hayan sido utilizados como subset de validación. <br>\n",
    "El resultado final del cross validation es el promedio del resultado de todas las iteraciones realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(train, subSetPercentage, funciones):\n",
    "    # La cantidad máxima de observaciones de un sub set.\n",
    "    subSetMaxSize = round(train.shape[0] * subSetPercentage) + 1\n",
    "    \n",
    "    # Los índices para el primer set de validación.\n",
    "    subSetStartIndex = 0\n",
    "    subSetEndIndex = subSetMaxSize\n",
    "    \n",
    "    # El máximo index de mi dataframe.\n",
    "    setMaxIndex = train.shape[0]\n",
    "    iteraciones = 0\n",
    "    acumulador = 0\n",
    "\n",
    "    while subSetStartIndex <= setMaxIndex:        \n",
    "        # Armo el set de entrenamiento y el set de validación.\n",
    "        validationSet = train[subSetStartIndex:subSetEndIndex]\n",
    "        trainSet = train.drop(train.index[subSetStartIndex:subSetEndIndex])\n",
    "        \n",
    "        # Empiezo el entrenamiento.\n",
    "        trainSet = splitTrainIntoWords(trainSet)\n",
    "        testSet = splitTestIntoWords(validationSet)\n",
    "        \n",
    "        # Aplico las funciones correspondientes al set de entrenamiento y de test.\n",
    "        trainSet, testSet = aplicarFunciones(trainSet, testSet, funciones)\n",
    "            \n",
    "        # Realizo las predicciones.\n",
    "        predicciones = entrenarPredecirYGuardar(trainSet, testSet, '', False)\n",
    "        puntaje = evaluarPredicciones(predicciones, validationSet)\n",
    "        \n",
    "        # Aumento los valores para una nueva iteración.\n",
    "        subSetStartIndex = subSetEndIndex + 1\n",
    "        subSetEndIndex = subSetStartIndex + subSetMaxSize\n",
    "        iteraciones = iteraciones + 1\n",
    "    \n",
    "        acumulador = acumulador + puntaje\n",
    "       \n",
    "    # Se devuelve el promedio de los puntajes obtenidos.\n",
    "    return acumulador / iteraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función grid search.\n",
    "En esta función lo que se hace es bucar la combinación de funciones que mejor resultado dan al predecir el test de entrenamiento mediante cross validation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(train):\n",
    "    # Grid search sobre todas las posibilidades para ver cuál ajusta mejor.\n",
    "    cantidadDeFunciones = 5\n",
    "    mejorResultado = 0\n",
    "    mejorCombinacion = [0, 0, 0, 0, 0]\n",
    "\n",
    "    for number in range(pow(2, cantidadDeFunciones)):\n",
    "        bits = [(number >> bit) & 1 for bit in range(cantidadDeFunciones - 1, -1, -1)]\n",
    "    \n",
    "        validacion = crossValidation(train, 0.1, bits)\n",
    "        \n",
    "        if validacion > mejorResultado:\n",
    "            mejorResultado = validacion\n",
    "            mejorCombinacion = bits\n",
    "            \n",
    "        print('Combinacion: ', bits, 'Resultado: ', validacion, 'Mejor resultado: ', mejorResultado, 'Mejor combinación: ', mejorCombinacion)\n",
    "    \n",
    "    return mejorResultado, mejorCombinacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se busca la mejor combinación mediante el gridSearch + cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainData.copy()\n",
    "resultado, combinacion = gridSearch(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se encontró la mejor combinación se usa la combinación para realizar predicciones sobre el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el nombre del archivo en el que se guardará el resultado.\n",
    "combinacionNombre = ''\n",
    "\n",
    "for value in combinacion:\n",
    "    combinacionNombre = combinacionNombre + str(value)\n",
    "\n",
    "nombreArchivo = 'test-' + combinacionNombre + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el train y el set con la combinación que dió mejor resultado.\n",
    "mejorTrain = splitTrainIntoWords(trainData)\n",
    "mejorTest = splitTestIntoWords(testData)\n",
    "mejorTrain, mejorTest = aplicarFunciones(mejorTrain, mejorTest, combinacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza la predicción y se guarda el archivo.\n",
    "entrenarPredecirYGuardar(mejorTrain, mejorTest, nombreArchivo, True)['target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
