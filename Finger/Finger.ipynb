{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo los archivos a utilizar. Solo las columnas de mi interés.\n",
    "trainData = pd.read_csv('../Data/train.csv', usecols=['id', 'text', 'target'])\n",
    "testData = pd.read_csv('../Data/test.csv', usecols=['id', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso el train y test set\n",
    "Obtengo el train set como (word, target) y el test set como (id, word)\n",
    "\n",
    "Me fijo cómo es la estructura de cada set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  10865  Storm in RI worse than last hurricane. My city...\n",
       "3260  10868  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  10875  #CityofCalgary has activated its Municipal Eme..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso el train para obtener (word, target)\n",
    "Es una función auxiliar que cambia la estructura del dataset de entrenamiendo de (id, text, target) a (word, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los textos de los tweets en palabras.\n",
    "def splitTrainIntoWords(dataframe):\n",
    "    splitted = pd.DataFrame(dataframe['text'].str.split(' ').to_list(), index=dataframe['id']).stack()\n",
    "    \n",
    "    # Reestablezco el id.\n",
    "    splitted = splitted.reset_index([0, 'id'])\n",
    "\n",
    "    # Le pongo a las segunda columna un nombre descriptivo.\n",
    "    splitted.columns = ['id','word']\n",
    "\n",
    "    # Agrego la columna target haciendo un merge con el set original.\n",
    "    splitted = splitted.merge(dataframe, left_on = 'id', right_on = 'id', how = 'left')\n",
    "\n",
    "    # Elimino la columna text y id.\n",
    "    del splitted['text']\n",
    "    del splitted['id']\n",
    "\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso el test set para obtener (id, word)\n",
    "Es una función auxiliar que cambia la estructura del dataset de test de (id, text) a (id, word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los textos de los tweets en palabras.\n",
    "def splitTestIntoWords(dataframe):\n",
    "    # Creo un nuevo dataframe con las palabras separadas.\n",
    "    splitted = pd.DataFrame(dataframe['text'].str.split(' ').to_list(), index=dataframe['id']).stack()\n",
    "    \n",
    "    # Reestablezco el id.\n",
    "    splitted = splitted.reset_index([0, 'id'])\n",
    "\n",
    "    # Le pongo a las segunda columna un nombre descriptivo.\n",
    "    splitted.columns = ['id','word']\n",
    "\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de entrenamiento\n",
    "Esta función toma el set de entrenamiento del formato (word, target) con el cuál se va a realizar el entrenamiento modelo y devuelve un dataframe entrenado del formato (word, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModelo(train):    \n",
    "    # Agrupo las palabras y hago un promedio del target.\n",
    "    trainedDF = train.groupby('word').mean().reset_index()\n",
    "    \n",
    "    return trainedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de predicción\n",
    "Esta función realiza las predicciones.\n",
    "\n",
    "Recibe un set entrenado con el formaro (word, target) y un set de test con el formato (id, word) sobre el cuál realiza las predicciones.\n",
    "\n",
    "Devuelve un dataframe con las predicciones del tipo (id, predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(trained, test, puntoLimite):    \n",
    "    # Mergeo el valor del promedio del target de las palabras en este data set.\n",
    "    testDF = test.merge(trained, left_on = 'word', right_on = 'word', how = 'left')\n",
    "    \n",
    "    # Elimino la columna de las palabras.\n",
    "    del testDF['word']\n",
    "    \n",
    "    # Agrupo por id.\n",
    "    testDF = testDF.groupby('id').mean().reset_index()\n",
    "    \n",
    "    # Paso los valores a 1 y 0 dependiendo si target >= puntoLimite o < puntoLimite.\n",
    "    testDF['target'] = testDF['target'].apply(lambda x: 1 if x >= puntoLimite else 0)\n",
    "    \n",
    "    return testDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para crear submit.\n",
    "Toma un set de datos de train con formaro (word, target), lo entrena, realiza las predicciones sobre el archivo test con formato (id, word) y guarda un archivo en caso de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarPredecirYGuardar(train, test, puntoLimite, csvFileName, save):\n",
    "    trained = entrenarModelo(train)\n",
    "    predicciones = predecir(trained, test, puntoLimite)  \n",
    "    \n",
    "    if save:\n",
    "        predicciones.set_index('id').to_csv(csvFileName)\n",
    "    \n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creo funciones que van a ser las que se aplican a los datasets para realizar la optimización.\n",
    "\n",
    "Para mejorar en cada iteración el resultado se crean diferentes funciones que hacen los siguientes cambios:\n",
    "\n",
    "1 - Se pasan todas las palabras a lowercase.\n",
    "\n",
    "2 - Se toman los links como si fueran una sola palabra 'http'.\n",
    "\n",
    "3 - Se quitan los '\\n' encontrados en los textos.\n",
    "\n",
    "4 - Se quitan los stop words.\n",
    "\n",
    "5 - Se quitan de las palabras todos los caracteres que no sean letras y se eliminan las palabras vacías.\n",
    "\n",
    "En cada paso se hará un nuevo submit verificando los resultados obtenidos.\n",
    "\n",
    "## Nomenclatura de los archivos\n",
    "Se tienen 5 funcionas a aplicar a los datasets, entonces los archivos se nombraran como finger-xxxxx.csv.\n",
    "\n",
    "Si solo se aplica la función 1 entonces el archivo sera finger-00001.csv, si no se aplica ninguna función será finger-00000.csv y si se aplican la función 1 y la función 3 será finger-00101.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para pasar las palabras a minúsculas\n",
    "Recibe un set de datos con una columna 'word' y devuelve un nuevo set con las palabras en minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabrasALowercase(trained):\n",
    "    lowercasedDF = trained.copy()\n",
    "    \n",
    "    # Paso las palabras a minúsculas.\n",
    "    lowercasedDF['word'] = lowercasedDF['word'].str.lower()\n",
    "    \n",
    "    return lowercasedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para tomar los links como una única palabra 'http'\n",
    "Recibe un set de datos con la columna 'word' y devuelve un nuevo set con los links como si fueran una misma palabra 'http'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linksComoHttp(trained):\n",
    "    httpDF = trained.copy()\n",
    "    \n",
    "    # Todos los links pasan a ser la palabra 'http'.\n",
    "    httpDF.loc[httpDF['word'].str.contains('http', case=True), 'word'] = 'http'\n",
    "    \n",
    "    return httpDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que quita los saltos de línea '\\n'\n",
    "Recibe un set de datos entrenados, un set de test del formato (word, target) o (id, word) y un train set o test set con los la etiquera '\\n' eliminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarEtiquetasTrain(train):\n",
    "    trainDF = train.copy()\n",
    "    trainDF = pd.DataFrame(trainDF['word'].str.split('\\n').to_list(), index=trainDF['target']).stack()\n",
    "    trainDF = trainDF.reset_index([0, 'target'])\n",
    "    trainDF.columns = ['target','word']\n",
    "    trainDF.reset_index()\n",
    "    \n",
    "    return trainDF\n",
    "\n",
    "def eliminarEtiquetasTest(test):\n",
    "    testDF = test.copy()\n",
    "    testDF = pd.DataFrame(testDF['word'].str.split('\\n').to_list(), index=testDF['id']).stack()\n",
    "    testDF = testDF.reset_index([0, 'id'])\n",
    "    testDF.columns = ['id','word']\n",
    "    testDF.reset_index()\n",
    "    \n",
    "    return testDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que quita todos los caracteres que no sean letras de las palabras.\n",
    "Dado un dataframe con la columna 'word', elimina caracteres especiales y borra todas las palabras que sean vacías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarCharsEspeciales(dataframe): \n",
    "    sanDF = dataframe.copy()\n",
    "    sanDF = sanDF[sanDF['word'].str.isspace() == False]\n",
    "    sanDF['word'].replace(regex=True, inplace=True, to_replace='[^A-Za-z]', value=r'')\n",
    "    sanDF = sanDF[sanDF['word'].str.strip().astype(bool)]\n",
    "    \n",
    "    return sanDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para quitar las stop words.\n",
    "Dado un dataframe con la columna 'word', elimina todos los stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarStopWords(dataframe):\n",
    "    stops = stopwords.words('english')\n",
    "    sinStops = dataframe.copy()\n",
    "    sinStops = sinStops[~sinStops['word'].isin(stops)]\n",
    "    return sinStops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submits.\n",
    "A continuación se realizan los submits de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2281\n",
       "1     982\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00000.\n",
    "trainSplitted = splitTrainIntoWords(trainData)\n",
    "testSplitted = splitTestIntoWords(testData)\n",
    "entrenarPredecirYGuardar(trainSplitted, testSplitted, 0.5, 'finger-00000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2293\n",
       "1     970\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00001.\n",
    "# Se aplica lowercase a las palabras de los dataframes.\n",
    "trainLowercased = palabrasALowercase(trainSplitted)\n",
    "testLowercase = palabrasALowercase(testSplitted)\n",
    "entrenarPredecirYGuardar(trainLowercased, testLowercase, 0.5, 'finger-00001.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2267\n",
       "1     996\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00010.\n",
    "# Se toman los links como la palabra 'http'.\n",
    "trainHTTP = linksComoHttp(trainSplitted)\n",
    "testHTTP = linksComoHttp(testSplitted)\n",
    "entrenarPredecirYGuardar(trainHTTP, testHTTP, 0.5, 'finger-00010.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2276\n",
       "1     987\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00100.\n",
    "# Se eliminan las etiquetas como '\\n'.\n",
    "trainSinEtiquetas = eliminarEtiquetasTrain(trainSplitted)\n",
    "testSinEtiquetas = eliminarEtiquetasTest(testSplitted)\n",
    "entrenarPredecirYGuardar(trainSinEtiquetas, testSinEtiquetas, 0.5, 'finger-00100.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2147\n",
       "1    1116\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 01000.\n",
    "# Se eliminan las stopwords.\n",
    "trainStops = eliminarStopWords(trainSplitted)\n",
    "testStops = eliminarStopWords(testSplitted)\n",
    "\n",
    "entrenarPredecirYGuardar(trainStops, testStops, 0.5, 'finger-01000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2305\n",
       "1     958\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000.\n",
    "# Se eliminan los caracteres especiales y las palabras vacías..\n",
    "trainSan = eliminarCharsEspeciales(trainSplitted)\n",
    "testSan = eliminarCharsEspeciales(testSplitted)\n",
    "entrenarPredecirYGuardar(trainSan, testSan, 0.5, 'finger-10000.csv', True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search + Cross validation.\n",
    "A continuación se intentaran buscar cuál es la combinación de funciones que mejores predicciones realiza.<br>\n",
    "La idea es buscar, dentro de las 5 funciones declaradas, las funciones que minimizan los errores de predicción. <br>\n",
    "Para cada combinación de funciones se dividirá el set de datos en 10 subsets, se entrenara el algoritmo con 9 subsets y se utilizará el subset restante como set de validación. Este proceso se realizará 10 veces con el fin de que cada subset actue como set de validación.<br>\n",
    "Una vez que se corrieron las 10 iteraciones para cada combinación de funciones, se tomara como resultado el promedio de los valores obtenidos para cada iteración y se elige aquela combinación que mejor resultado logró.\n",
    "\n",
    "## Función que aplica las funciones declaradas \n",
    "Esta función lo que hace es recibir una lista de enteros que indican si la función se debe aplicar o no dependiendo si en la posición se encuentra un 1 o un 0. Por ejemplo: si se recibe la lista [0, 1, 1, 0, 0] esto indica lo siguiente: <br>\n",
    "0 -> No se aplica la función 5.<br>\n",
    "1 -> Se aplica la función 4.<br>\n",
    "1 -> Se aplica la función 3.<br>\n",
    "0 -> No se aplica la función 2.<br>\n",
    "0 -> No se aplica la función 1.<br>\n",
    "\n",
    "El set de entrenamiento y el de test tienen que tener los siguientes formatos: (word, target) y (id, word) respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarFunciones(train, test, funciones):\n",
    "    trainSet = train.copy()\n",
    "    testSet = test.copy()\n",
    "    \n",
    "    if funciones[4]:\n",
    "        trainSet = palabrasALowercase(trainSet)\n",
    "        testSet = palabrasALowercase(testSet)\n",
    "        \n",
    "    if funciones[3]:\n",
    "        trainSet = linksComoHttp(trainSet)\n",
    "        testSet = linksComoHttp(testSet)\n",
    "        \n",
    "    if funciones[2]:\n",
    "        trainSet = eliminarEtiquetasTrain(trainSet)\n",
    "        testSet = eliminarEtiquetasTest(testSet)\n",
    "        \n",
    "    if funciones[1]:\n",
    "        trainSet = eliminarStopWords(trainSet)\n",
    "        testSet = eliminarStopWords(testSet)\n",
    "        \n",
    "    if funciones[0]:\n",
    "        trainSet = eliminarCharsEspeciales(trainSet)\n",
    "        testSet = eliminarCharsEspeciales(testSet)\n",
    "        \n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de evaluación\n",
    "Esta función recibe un dataframe de predicciones (id, target) con su dataframe de validación (id, target). <br>\n",
    "Simplemente valida si se realizó bien o mal la predicción y, mediante los positivos verdaderos, los falsos positivos y falsos negativos, calcula la función F1 de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluarPredicciones(predicciones, validaciones):\n",
    "    verdaderoPositivo = 0\n",
    "    falsoPositivo = 0\n",
    "    falsoNegativo = 0\n",
    "    \n",
    "    for i in range(0, predicciones.shape[0] - 1):\n",
    "        prediccion = predicciones.iloc[i, :]\n",
    "        idPrediccion = prediccion['id']\n",
    "        valorReal = validaciones[validaciones['id'] == idPrediccion].iloc[0,:]\n",
    "\n",
    "        prediccionTarget = prediccion['target']\n",
    "        valorRealTarget = valorReal['target']\n",
    "    \n",
    "        if prediccionTarget == 1 and valorRealTarget == 1:\n",
    "            verdaderoPositivo = verdaderoPositivo + 1\n",
    "            \n",
    "        if prediccionTarget == 1 and valorRealTarget == 0:\n",
    "            falsoPositivo = falsoPositivo + 1\n",
    "                \n",
    "        if prediccionTarget == 0 and valorRealTarget == 1:\n",
    "            falsoNegativo = falsoNegativo + 1\n",
    "    \n",
    "    if verdaderoPositivo + falsoPositivo == 0:\n",
    "        return 0\n",
    "            \n",
    "    precision = verdaderoPositivo / (verdaderoPositivo + falsoPositivo)\n",
    "    recall = verdaderoPositivo / (verdaderoPositivo + falsoNegativo)\n",
    "    \n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función cross validation\n",
    "Esta función realiza el proceso de validación para la combinación de funciones recibida. <br>\n",
    "Dado el set de entrenamiento (id, word, target) y el porcentage por el cuál dividir el train divide el set de entrenamiento en dos sub set: set de entrenamiento (uno nuevo, de menor tamaño) y set de validación. <br>\n",
    "A partir del set de validación genera un set de testeo, sobre el cuál se van a realizar las predicciones. <br>\n",
    "Se entrena el modelo con el subset de entrenamiento y se realizan las predicciones sobre el set de testeo. <br>\n",
    "Se itera hasta que todos los subsets que se pueden armar con el porcentage de subsets pasado hayan sido utilizados como subset de validación. <br>\n",
    "El resultado final del cross validation es el promedio del resultado de todas las iteraciones realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(train, subSetPercentage, funciones, puntoLimite):\n",
    "    # La cantidad máxima de observaciones de un sub set.\n",
    "    subSetMaxSize = round(train.shape[0] * subSetPercentage) + 1\n",
    "    \n",
    "    # Los índices para el primer set de validación.\n",
    "    subSetStartIndex = 0\n",
    "    subSetEndIndex = subSetMaxSize\n",
    "    \n",
    "    # El máximo index de mi dataframe.\n",
    "    setMaxIndex = train.shape[0]\n",
    "    iteraciones = 0\n",
    "    acumulador = 0\n",
    "\n",
    "    while subSetStartIndex <= setMaxIndex:        \n",
    "        # Armo el set de entrenamiento y el set de validación.\n",
    "        validationSet = train[subSetStartIndex:subSetEndIndex]\n",
    "        trainSet = train.drop(train.index[subSetStartIndex:subSetEndIndex])\n",
    "        \n",
    "        # Empiezo el entrenamiento.\n",
    "        trainSet = splitTrainIntoWords(trainSet)\n",
    "        testSet = splitTestIntoWords(validationSet)\n",
    "        \n",
    "        # Aplico las funciones correspondientes al set de entrenamiento y de test.\n",
    "        trainSet, testSet = aplicarFunciones(trainSet, testSet, funciones)\n",
    "            \n",
    "        # Realizo las predicciones.\n",
    "        predicciones = entrenarPredecirYGuardar(trainSet, testSet, puntoLimite, '', False)\n",
    "        puntaje = evaluarPredicciones(predicciones, validationSet)\n",
    "        \n",
    "        # Aumento los valores para una nueva iteración.\n",
    "        subSetStartIndex = subSetEndIndex + 1\n",
    "        subSetEndIndex = subSetStartIndex + subSetMaxSize\n",
    "        iteraciones = iteraciones + 1\n",
    "    \n",
    "        acumulador = acumulador + puntaje\n",
    "       \n",
    "    # Se devuelve el promedio de los puntajes obtenidos.\n",
    "    return acumulador / iteraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función grid search.\n",
    "En esta función lo que se hace es bucar la combinación de funciones que mejor resultado dan al predecir el test de entrenamiento mediante cross validation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(train):\n",
    "    # Grid search sobre todas las posibilidades para ver cuál ajusta mejor.\n",
    "    cantidadDeFunciones = 5\n",
    "    mejorResultado = 0\n",
    "    mejorCombinacion = [0, 0, 0, 0, 0]\n",
    "    puntoLimite = 0.0\n",
    "    puntoLimiteVar = 0.1\n",
    "    mejorPuntoLimite = 0.0\n",
    "    \n",
    "    while puntoLimite <= 1:\n",
    "        print('############################################################################################################')\n",
    "        print('Punto Límite: ', puntoLimite)\n",
    "        print('############################################################################################################')\n",
    "\n",
    "        for number in range(pow(2, cantidadDeFunciones)):\n",
    "            bits = [(number >> bit) & 1 for bit in range(cantidadDeFunciones - 1, -1, -1)]\n",
    "            \n",
    "            validacion = crossValidation(train, 0.1, bits, puntoLimite)\n",
    "            \n",
    "            if validacion > mejorResultado:\n",
    "                mejorResultado = validacion\n",
    "                mejorCombinacion = bits\n",
    "                mejorPuntoLimite = puntoLimite\n",
    "            \n",
    "            print('Comb: ', bits, '; Res: ', validacion, '; Mejor Res: ', mejorResultado, '; Mejor Comb: ', mejorCombinacion)\n",
    "        \n",
    "        puntoLimite = puntoLimite + puntoLimiteVar\n",
    "    \n",
    "    return mejorResultado, mejorCombinacion, puntoLimite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se busca la mejor combinación mediante el gridSearch + cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainData.copy()\n",
    "resultado, combinacion, puntoLimite = gridSearch(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se encontró la mejor combinación se usa la combinación para realizar predicciones sobre el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el nombre del archivo en el que se guardará el resultado.\n",
    "nombreArchivo = 'finger-best.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el train y el set con la combinación que dió mejor resultado.\n",
    "mejorTrain = splitTrainIntoWords(trainData)\n",
    "mejorTest = splitTestIntoWords(testData)\n",
    "mejorTrain, mejorTest = aplicarFunciones(mejorTrain, mejorTest, [1,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2137\n",
       "1    1126\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se realiza la predicción y se guarda el archivo.\n",
    "entrenarPredecirYGuardar(mejorTrain, mejorTest, 0.5, nombreArchivo, True)['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
